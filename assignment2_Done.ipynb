{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCDster/IntroToMachineLearning/blob/main/assignment2_Done.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling and Exploratory Data Analysis\n",
        "## Do Q1 and Q2, and one other question.\n",
        "`! git clone https://www.github.com/DS3001/assignment2`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I did Q1, Q2, and Q5**"
      ],
      "metadata": {
        "id": "ZrhG-3aH3Jc5"
      },
      "id": "ZrhG-3aH3Jc5"
    },
    {
      "cell_type": "markdown",
      "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
      "metadata": {
        "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
      },
      "source": [
        "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
        "\n",
        "  1. Read the abstract. What is this paper about?\n",
        "  -This paper is about how to tidy data into a consistant and easy to work with structure in the most effiecient way possible.\n",
        "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
        "  -It is intended to make a standard for data sets so that functions can be uniformly applied to data sets, making data easier to analyse.\n",
        "  3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, itâ€™s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
        "  -Based on the Tolstoy quote, it means that all tidy data sets are the same in meaning and complete in the same way. Messy data sets however are uniquely messy, with no overarching factor to the mess.\n",
        "  -Variables messure an underlying value across units where observations messure the same units across attributes. Its hard to define a systimatic way to tell what is a variable and what is a observation, but it's easy to percieve this difference.\n",
        "  4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
        "  -A value is any number or string collected in the data set. The value is a variable if it is messured on attributes across units but a observation if its mesured across units across attributes.\n",
        "  5. How is \"Tidy Data\" defined in section 2.3?\n",
        "  -each variable has a row, each observation has a column, each type of observational unit forms a table\n",
        "  6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
        "  -The 5 most common: Column headers are values, not variable names, multiple variables are stored in one column, variables are stored in both rows and columns, multiple types of observational units are stored in the same table, and a single observational unit is stored in multiple tables. Table 4 is messy because it has three variables, religion, income and frequncy, two of which are stored as columns and one in the rows. Melting is converting columns into rows of data.\n",
        "  7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
        "  -This is because the variable day was stored as a column in table 11, but turned into a row for table 12 by using a full date and value format.\n",
        "  8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?\n",
        "  -The chicken-and-egg problem is that tidy data is only useful as long as there are tools for that tidy data and tools will be linked only to tidy data. He hopes that more people will work on tidy data structures, formats, and tools in order to make tidying data easier, and tools better at using the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
        "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://www.github.com/DS3001/assignment2\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzvltCMRgv-r",
        "outputId": "5eef83fe-227f-4757-fa90-374666c18f81"
      },
      "id": "xzvltCMRgv-r",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assignment2'...\n",
            "warning: redirecting to https://github.com/DS3001/assignment2.git/\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 36 (delta 8), reused 5 (delta 5), pack-reused 24\u001b[K\n",
            "Receiving objects: 100% (36/36), 5.47 MiB | 15.09 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # Import the numpy package into your workspace\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tWrHjI1ghxWK"
      },
      "id": "tWrHjI1ghxWK",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start of Part 1\n",
        "df = pd.read_csv('assignment2/data/airbnb_hw.csv',low_memory=False)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "lAYP-g_diDGY",
        "outputId": "3245a78c-11a8-4a76-d737-11e934d82afc"
      },
      "id": "lAYP-g_diDGY",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Host Id Host Since                                Name Neighbourhood   \\\n",
              "0   5162530        NaN     1 Bedroom in Prime Williamsburg       Brooklyn   \n",
              "1  33134899        NaN     Sunny, Private room in Bushwick       Brooklyn   \n",
              "2  39608626        NaN                Sunny Room in Harlem      Manhattan   \n",
              "3       500  6/26/2008  Gorgeous 1 BR with Private Balcony      Manhattan   \n",
              "4       500  6/26/2008            Trendy Times Square Loft      Manhattan   \n",
              "\n",
              "  Property Type  Review Scores Rating (bin)        Room Type  Zipcode  Beds  \\\n",
              "0     Apartment                         NaN  Entire home/apt  11249.0   1.0   \n",
              "1     Apartment                         NaN     Private room  11206.0   1.0   \n",
              "2     Apartment                         NaN     Private room  10032.0   1.0   \n",
              "3     Apartment                         NaN  Entire home/apt  10024.0   3.0   \n",
              "4     Apartment                        95.0     Private room  10036.0   3.0   \n",
              "\n",
              "   Number of Records  Number Of Reviews Price  Review Scores Rating  \n",
              "0                  1                  0   145                   NaN  \n",
              "1                  1                  1    37                   NaN  \n",
              "2                  1                  1    28                   NaN  \n",
              "3                  1                  0   199                   NaN  \n",
              "4                  1                 39   549                  96.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eda09726-6505-4398-ab2d-673e1b279f7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Host Id</th>\n",
              "      <th>Host Since</th>\n",
              "      <th>Name</th>\n",
              "      <th>Neighbourhood</th>\n",
              "      <th>Property Type</th>\n",
              "      <th>Review Scores Rating (bin)</th>\n",
              "      <th>Room Type</th>\n",
              "      <th>Zipcode</th>\n",
              "      <th>Beds</th>\n",
              "      <th>Number of Records</th>\n",
              "      <th>Number Of Reviews</th>\n",
              "      <th>Price</th>\n",
              "      <th>Review Scores Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5162530</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 Bedroom in Prime Williamsburg</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>11249.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33134899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sunny, Private room in Bushwick</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private room</td>\n",
              "      <td>11206.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39608626</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sunny Room in Harlem</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Private room</td>\n",
              "      <td>10032.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "      <td>6/26/2008</td>\n",
              "      <td>Gorgeous 1 BR with Private Balcony</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>10024.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>199</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "      <td>6/26/2008</td>\n",
              "      <td>Trendy Times Square Loft</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>95.0</td>\n",
              "      <td>Private room</td>\n",
              "      <td>10036.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>549</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eda09726-6505-4398-ab2d-673e1b279f7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eda09726-6505-4398-ab2d-673e1b279f7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eda09726-6505-4398-ab2d-673e1b279f7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d628832-6534-45e2-9c3b-50b388afd084\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d628832-6534-45e2-9c3b-50b388afd084')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d628832-6534-45e2-9c3b-50b388afd084 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Price'].unique(),'\\n') # 'n' is not listed in the codebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17RCWwAKiX_T",
        "outputId": "1d1d051a-2c7f-446a-dc32-0efe2e2beba9"
      },
      "id": "17RCWwAKiX_T",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['145' '37' '28' '199' '549' '149' '250' '90' '270' '290' '170' '59' '49'\n",
            " '68' '285' '75' '100' '150' '700' '125' '175' '40' '89' '95' '99' '499'\n",
            " '120' '79' '110' '180' '143' '230' '350' '135' '85' '60' '70' '55' '44'\n",
            " '200' '165' '115' '74' '84' '129' '50' '185' '80' '190' '140' '45' '65'\n",
            " '225' '600' '109' '1,990' '73' '240' '72' '105' '155' '160' '42' '132'\n",
            " '117' '295' '280' '159' '107' '69' '239' '220' '399' '130' '375' '585'\n",
            " '275' '139' '260' '35' '133' '300' '289' '179' '98' '195' '29' '27' '39'\n",
            " '249' '192' '142' '169' '1,000' '131' '138' '113' '122' '329' '101' '475'\n",
            " '238' '272' '308' '126' '235' '315' '248' '128' '56' '207' '450' '215'\n",
            " '210' '385' '445' '136' '247' '118' '77' '76' '92' '198' '205' '299'\n",
            " '222' '245' '104' '153' '349' '114' '320' '292' '226' '420' '500' '325'\n",
            " '307' '78' '265' '108' '123' '189' '32' '58' '86' '219' '800' '335' '63'\n",
            " '229' '425' '67' '87' '1,200' '158' '650' '234' '310' '695' '400' '166'\n",
            " '119' '62' '168' '340' '479' '43' '395' '144' '52' '47' '529' '187' '209'\n",
            " '233' '82' '269' '163' '172' '305' '156' '550' '435' '137' '124' '48'\n",
            " '279' '330' '5,000' '134' '378' '97' '277' '64' '193' '147' '186' '264'\n",
            " '30' '3,000' '112' '94' '379' '57' '415' '236' '410' '214' '88' '66' '71'\n",
            " '171' '157' '545' '1,500' '83' '96' '1,800' '81' '188' '380' '255' '505'\n",
            " '54' '33' '174' '93' '740' '640' '1,300' '440' '599' '357' '1,239' '495'\n",
            " '127' '5,999' '178' '348' '152' '242' '183' '253' '750' '259' '365' '273'\n",
            " '197' '397' '103' '389' '355' '559' '38' '203' '999' '141' '162' '333'\n",
            " '698' '46' '360' '895' '10' '41' '206' '281' '449' '388' '212' '102'\n",
            " '201' '2,750' '4,750' '432' '675' '167' '390' '298' '339' '194' '302'\n",
            " '211' '595' '191' '53' '361' '480' '8,000' '4,500' '459' '997' '345'\n",
            " '216' '218' '111' '735' '276' '91' '490' '850' '398' '36' '775' '267'\n",
            " '625' '336' '2,500' '176' '725' '3,750' '469' '106' '460' '287' '575'\n",
            " '227' '263' '25' '228' '208' '177' '880' '148' '116' '685' '470' '217'\n",
            " '164' '61' '645' '699' '405' '252' '319' '268' '419' '343' '525' '311'\n",
            " '840' '154' '294' '950' '409' '184' '257' '204' '241' '2,000' '412' '121'\n",
            " '288' '196' '900' '647' '524' '1,750' '309' '510' '1,495' '1,700' '799'\n",
            " '383' '372' '492' '327' '1,999' '656' '224' '173' '875' '1,170' '795'\n",
            " '690' '146' '465' '1,100' '151' '274' '429' '825' '282' '256' '1,111'\n",
            " '620' '271' '161' '51' '855' '579' '1,174' '430' '20' '899' '649' '485'\n",
            " '181' '455' '4,000' '243' '342' '590' '560' '374' '437' '232' '359' '985'\n",
            " '31' '244' '254' '723' '237' '428' '370' '34' '1,400' '580' '2,520' '221'\n",
            " '749' '1,600' '2,695' '306' '202' '680' '570' '520' '223' '2,295' '213'\n",
            " '1,065' '346' '24' '286' '296' '266' '26' '995' '1,368' '393' '182' '635'\n",
            " '258' '780' '589' '347' '1,250' '1,350' '446' '3,200' '1,050' '1,650'\n",
            " '1,550' '975' '323' '6,500' '2,499' '1,850' '2,250' '715' '461' '540'\n",
            " '356' '439' '384' '569' '1,900' '22' '785' '626' '830' '318' '444' '321'\n",
            " '401' '1,499' '888' '369' '770' '386' '366' '344' '630' '313' '597' '262'\n",
            " '509' '10,000' '278' '312' '789' '1,195' '422' '21' '765' '3,500' '945'\n",
            " '326' '3,100' '2,486' '3,390' '1,356' '2,599' '472' '454' '328' '396'\n",
            " '291'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I'm so sure there is a better way to do this but here goes nothing\n",
        "df['Price'] = df['Price'].replace('3,390','3390') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,356','1356') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,599','2599') # Notice the column replacement\n",
        "\n",
        "\n",
        "df['Price'] = df['Price'].replace('10,000','10000') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,1995','1195') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('3,500','3500') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('3,100','3100') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,486','2486') # Notice the column replacement\n",
        "\n",
        "\n",
        "df['Price'] = df['Price'].replace('1,550','1550') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('6,500','6500') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,499','2499') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,850','1850') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,250','2250') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,900','1900') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,499','1499') # Notice the column replacement\n",
        "\n",
        "\n",
        "df['Price'] = df['Price'].replace('1,368','1368') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,250','1250') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,350','135o') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('3,200','3200') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,050','1050') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,650','1650') # Notice the column replacement\n",
        "\n",
        "df['Price'] = df['Price'].replace('2,520','2520') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,600','1600') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,695','2695') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,295','2295') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,065','1065') # Notice the column replacement\n",
        "\n",
        "\n",
        "df['Price'] = df['Price'].replace('1,111','1111') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,174','1174') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('4,000','4000') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,400','1400') # Notice the column replacement\n",
        "\n",
        "\n",
        "df['Price'] = df['Price'].replace('1,700','1700') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,999','1999') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,170','1170') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,100','1100') # Notice the column replacement\n",
        "\n",
        "df['Price'] = df['Price'].replace('1,750','1750') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,495','1495') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,900','1900') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,990','1990') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,000','1000') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,200','1200') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('3,000','3000') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,300','1300') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('1,239','1239') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('5,999','5999') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,750','2750') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('4,750','4750') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('8,000','8000') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,500','2500') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('4,500','4500') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('5,000','5000') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('3,750','3750') # Notice the column replacement\n",
        "df['Price'] = df['Price'].replace('2,000','2000') # Notice the column replacement\n"
      ],
      "metadata": {
        "id": "e7PYEMQLkFZh"
      },
      "id": "e7PYEMQLkFZh",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Price'] = pd.to_numeric(df['Price'], errors='coerce') # Coerce the variable to numeric\n",
        "print(df['Price'].unique())\n",
        "#ENDED WITH NO MISSING VALUES!\n",
        "#END Part 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjmbZo0lpasK",
        "outputId": "90170611-e4fd-4f0d-e202-28227bcca9b6"
      },
      "id": "kjmbZo0lpasK",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  145.    37.    28.   199.   549.   149.   250.    90.   270.   290.\n",
            "   170.    59.    49.    68.   285.    75.   100.   150.   700.   125.\n",
            "   175.    40.    89.    95.    99.   499.   120.    79.   110.   180.\n",
            "   143.   230.   350.   135.    85.    60.    70.    55.    44.   200.\n",
            "   165.   115.    74.    84.   129.    50.   185.    80.   190.   140.\n",
            "    45.    65.   225.   600.   109.  1990.    73.   240.    72.   105.\n",
            "   155.   160.    42.   132.   117.   295.   280.   159.   107.    69.\n",
            "   239.   220.   399.   130.   375.   585.   275.   139.   260.    35.\n",
            "   133.   300.   289.   179.    98.   195.    29.    27.    39.   249.\n",
            "   192.   142.   169.  1000.   131.   138.   113.   122.   329.   101.\n",
            "   475.   238.   272.   308.   126.   235.   315.   248.   128.    56.\n",
            "   207.   450.   215.   210.   385.   445.   136.   247.   118.    77.\n",
            "    76.    92.   198.   205.   299.   222.   245.   104.   153.   349.\n",
            "   114.   320.   292.   226.   420.   500.   325.   307.    78.   265.\n",
            "   108.   123.   189.    32.    58.    86.   219.   800.   335.    63.\n",
            "   229.   425.    67.    87.  1200.   158.   650.   234.   310.   695.\n",
            "   400.   166.   119.    62.   168.   340.   479.    43.   395.   144.\n",
            "    52.    47.   529.   187.   209.   233.    82.   269.   163.   172.\n",
            "   305.   156.   550.   435.   137.   124.    48.   279.   330.  5000.\n",
            "   134.   378.    97.   277.    64.   193.   147.   186.   264.    30.\n",
            "  3000.   112.    94.   379.    57.   415.   236.   410.   214.    88.\n",
            "    66.    71.   171.   157.   545.    nan    83.    96.    81.   188.\n",
            "   380.   255.   505.    54.    33.   174.    93.   740.   640.  1300.\n",
            "   440.   599.   357.  1239.   495.   127.  5999.   178.   348.   152.\n",
            "   242.   183.   253.   750.   259.   365.   273.   197.   397.   103.\n",
            "   389.   355.   559.    38.   203.   999.   141.   162.   333.   698.\n",
            "    46.   360.   895.    10.    41.   206.   281.   449.   388.   212.\n",
            "   102.   201.  2750.  4750.   432.   675.   167.   390.   298.   339.\n",
            "   194.   302.   211.   595.   191.    53.   361.   480.  8000.  4500.\n",
            "   459.   997.   345.   216.   218.   111.   735.   276.    91.   490.\n",
            "   850.   398.    36.   775.   267.   625.   336.  2500.   176.   725.\n",
            "  3750.   469.   106.   460.   287.   575.   227.   263.    25.   228.\n",
            "   208.   177.   880.   148.   116.   685.   470.   217.   164.    61.\n",
            "   645.   699.   405.   252.   319.   268.   419.   343.   525.   311.\n",
            "   840.   154.   294.   950.   409.   184.   257.   204.   241.  2000.\n",
            "   412.   121.   288.   196.   900.   647.   524.  1750.   309.   510.\n",
            "  1495.  1700.   799.   383.   372.   492.   327.  1999.   656.   224.\n",
            "   173.   875.  1170.   795.   690.   146.   465.  1100.   151.   274.\n",
            "   429.   825.   282.   256.  1111.   620.   271.   161.    51.   855.\n",
            "   579.  1174.   430.    20.   899.   649.   485.   181.   455.  4000.\n",
            "   243.   342.   590.   560.   374.   437.   232.   359.   985.    31.\n",
            "   244.   254.   723.   237.   428.   370.    34.  1400.   580.  2520.\n",
            "   221.   749.  1600.  2695.   306.   202.   680.   570.   520.   223.\n",
            "  2295.   213.  1065.   346.    24.   286.   296.   266.    26.   995.\n",
            "  1368.   393.   182.   635.   258.   780.   589.   347.  1250.   446.\n",
            "  3200.  1050.  1650.  1550.   975.   323.  6500.  2499.  1850.  2250.\n",
            "   715.   461.   540.   356.   439.   384.   569.  1900.    22.   785.\n",
            "   626.   830.   318.   444.   321.   401.  1499.   888.   369.   770.\n",
            "   386.   366.   344.   630.   313.   597.   262.   509. 10000.   278.\n",
            "   312.   789.   422.    21.   765.  3500.   945.   326.  3100.  2486.\n",
            "  3390.  1356.  2599.   472.   454.   328.   396.   291.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 2 ./data/sharks.csv\n",
        "dff = pd.read_csv('assignment2/data/sharks.csv',low_memory=False)\n",
        "dff.head()\n",
        "print(dff['Type'].unique())\n",
        "print(dff['Type'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TWHDtFNp_6C",
        "outputId": "2beb359d-bf0a-4abf-b2aa-4ea104829e71"
      },
      "id": "_TWHDtFNp_6C",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unprovoked' 'Provoked' 'Questionable' 'Watercraft' 'Unconfirmed'\n",
            " 'Unverified' 'Invalid' 'Under investigation' 'Boating' 'Sea Disaster' nan\n",
            " 'Boat' 'Boatomg']\n",
            "Unprovoked             4716\n",
            "Provoked                593\n",
            "Invalid                 552\n",
            "Sea Disaster            239\n",
            "Watercraft              142\n",
            "Boat                    109\n",
            "Boating                  92\n",
            "Questionable             10\n",
            "Unconfirmed               1\n",
            "Unverified                1\n",
            "Under investigation       1\n",
            "Boatomg                   1\n",
            "Name: Type, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dff['Type'] = dff['Type'].replace(['Boating','Boat', 'Boatomg', 'Sea Disaster'],'Watercraft') # Moved anything Boat related to Watercraft catigory\n",
        "dff['Type'] = dff['Type'].replace(['Unverified','Under investigation', 'Unconfirmed'],'Questionable') # Moved anything in question to the Unconfirmed catigory\n",
        "dff['Type'] = dff['Type'].replace(['Invalid'], np.nan) # Made anything invalid null\n"
      ],
      "metadata": {
        "id": "FWRm2kjvrAUc"
      },
      "id": "FWRm2kjvrAUc",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dff['Type'].unique())\n",
        "print(dff['Type'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRCsCPvHsL2J",
        "outputId": "70a3ca38-f299-4873-b3ee-594d2cfdaf56"
      },
      "id": "YRCsCPvHsL2J",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unprovoked' 'Provoked' 'Questionable' 'Watercraft' nan]\n",
            "Unprovoked      4716\n",
            "Provoked         593\n",
            "Watercraft       583\n",
            "Questionable      13\n",
            "Name: Type, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I cleaned this so that there are 4 main groups of data, and any invalid data was marked as null so that it would not be marked as real data.\n",
        "End of Part 2"
      ],
      "metadata": {
        "id": "JZ_u-LIzs4wS"
      },
      "id": "JZ_u-LIzs4wS"
    },
    {
      "cell_type": "code",
      "source": [
        "#Start of Part 3\n",
        "url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'\n",
        "df1 = pd.read_csv(url,low_memory=False) # Pandas downloads and loads the .csv file for you"
      ],
      "metadata": {
        "id": "zd6zKmAetowX"
      },
      "id": "zd6zKmAetowX",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1['WhetherDefendantWasReleasedPretrial'].unique())\n",
        "df1['WhetherDefendantWasReleasedPretrial'] = df1['WhetherDefendantWasReleasedPretrial'].replace(9, np.nan) # Made anything invalid null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bim3V0kt9bD",
        "outputId": "d8e1f6d9-3233-454c-e389-68e551080825"
      },
      "id": "9bim3V0kt9bD",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1['WhetherDefendantWasReleasedPretrial'].unique())\n",
        "#End of Part 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcBeSM-su2Kk",
        "outputId": "8275c7d8-2fc7-4581-acf5-3d413ae58909"
      },
      "id": "kcBeSM-su2Kk",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nan  0.  1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start of Part 4\n",
        "print(df1['ImposedSentenceAllChargeInContactEvent'].unique)\n",
        "print(df1['ImposedSentenceAllChargeInContactEvent'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j99SMUFxvDxG",
        "outputId": "16a32fae-cf38-4274-f910-3ae469f557f7"
      },
      "id": "j99SMUFxvDxG",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Series.unique of 0                        \n",
            "1                      60\n",
            "2                      12\n",
            "3        .985626283367556\n",
            "4                        \n",
            "               ...       \n",
            "22981                    \n",
            "22982                    \n",
            "22983                    \n",
            "22984                    \n",
            "22985                    \n",
            "Name: ImposedSentenceAllChargeInContactEvent, Length: 22986, dtype: object>\n",
            "                    9053\n",
            "0                   4953\n",
            "12                  1404\n",
            ".985626283367556    1051\n",
            "6                    809\n",
            "                    ... \n",
            "49.9712525667351       1\n",
            "57.0349075975359       1\n",
            "79.9260780287474       1\n",
            "42.1642710472279       1\n",
            "1.6570841889117        1\n",
            "Name: ImposedSentenceAllChargeInContactEvent, Length: 484, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking at this data I see that it is all mostly integer numbers with some doubles, and a lot of missing data. I believe it represents the amount of days in prison a person gets sentinced to based on all Charges. I believe, looking at the data that if there is missing data this means that there was no sentince imposed on them so missing values should be replaced with a 0 value."
      ],
      "metadata": {
        "id": "JVLUe8gHxFOe"
      },
      "id": "JVLUe8gHxFOe"
    },
    {
      "cell_type": "code",
      "source": [
        "df1['ImposedSentenceAllChargeInContactEvent'] = pd.to_numeric(df1['ImposedSentenceAllChargeInContactEvent'], errors='coerce') # Coerce the variable to numeric\n",
        "df1['ImposedSentenceAllChargeInContactEvent'] = df1['ImposedSentenceAllChargeInContactEvent'].replace([np.nan, np.NaN], 0) # Made anything invalid null\n",
        "\n",
        "print(df1['ImposedSentenceAllChargeInContactEvent'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPa8wG-azQLr",
        "outputId": "23ef80fb-fb76-4490-d27e-d7f54c3f1574"
      },
      "id": "yPa8wG-azQLr",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.000000     14006\n",
            "12.000000     1404\n",
            "0.985626      1051\n",
            "6.000000       809\n",
            "3.000000       787\n",
            "             ...  \n",
            "49.971253        1\n",
            "57.034908        1\n",
            "79.926078        1\n",
            "42.164271        1\n",
            "1.657084         1\n",
            "Name: ImposedSentenceAllChargeInContactEvent, Length: 483, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To clean this code I changed the data to a numeric then replaced any missing value with a 0 as I mean a missing value means there was no charges brought so that there was no imposed sentince on the person with no value.\n",
        "End of part 4."
      ],
      "metadata": {
        "id": "SkWHem6A2abs"
      },
      "id": "SkWHem6A2abs"
    },
    {
      "cell_type": "markdown",
      "id": "c11bcd96-2834-41a4-80fe-d354b4277fd9",
      "metadata": {
        "id": "c11bcd96-2834-41a4-80fe-d354b4277fd9"
      },
      "source": [
        "**Q3.** This question provides some practice doing exploratory data analysis and visualization.\n",
        "\n",
        "The \"relevant\" variables for this question are:\n",
        "  - `level` - Level of institution (4-year, 2-year)\n",
        "  - `aid_value` - The average amount of student aid going to undergraduate recipients\n",
        "  - `control` - Public, Private not-for-profit, Private for-profit\n",
        "  - `grad_100_value` - percentage of first-time, full-time, degree-seeking undergraduates who complete a degree or certificate program within 100 percent of expected time (bachelor's-seeking group at 4-year institutions)\n",
        "\n",
        "1. Load the `./data/college_completion.csv` data with Pandas.\n",
        "2. What are are the dimensions of the data? How many observations are there? What are the variables included? Use `.head()` to examine the first few rows of data.\n",
        "3. Cross tabulate `control` and `level`. Describe the patterns you see.\n",
        "4. For `grad_100_value`, create a histogram, kernel density plot, boxplot, and statistical description.\n",
        "5. For `grad_100_value`, create a grouped kernel density plot by `control` and by `level`. Describe what you see. Use `groupby` and `.describe` to make grouped calculations of statistical descriptions of `grad_100_value` by `level` and `control`. Which institutions appear to have the best graduation rates?\n",
        "6. Create a new variable, `df['levelXcontrol']=df['level']+', '+df['control']` that interacts level and control. Make a grouped kernel density plot. Which institutions appear to have the best graduation rates?\n",
        "7. Make a kernel density plot of `aid_value`. Notice that your graph is \"bi-modal\", having two little peaks that represent locally most common values. Now group your graph by `level` and `control`. What explains the bi-modal nature of the graph? Use `groupby` and `.describe` to make grouped calculations of statistical descriptions of `aid_value` by `level` and `control`.\n",
        "8. Make a scatterplot of `grad_100_value` by `aid_value`. Describe what you see. Now make the same plot, grouping by `level` and then `control`. Describe what you see. For which kinds of institutions does aid seem to increase graduation rates?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d34a3b-c21d-4dc9-a8d2-fb7686804ceb",
      "metadata": {
        "id": "98d34a3b-c21d-4dc9-a8d2-fb7686804ceb"
      },
      "source": [
        "**Q4.** This question uses the Airbnb data to practice making visualizations.\n",
        "\n",
        "  1. Load the `./data/airbnb_hw.csv` data with Pandas. You should have cleaned the `Price` variable in question 2, and you'll need it later for this question.\n",
        "  2. What are are the dimensions of the data? How many observations are there? What are the variables included? Use `.head()` to examine the first few rows of data.\n",
        "  3. Cross tabulate `Room Type` and `Property Type`. What patterns do you see in what kinds of rentals are available? For which kinds of properties are private rooms more common than renting the entire property?\n",
        "  4. For `Price`, make a histogram, kernel density, box plot, and a statistical description of the variable. Are the data badly scaled? Are there many outliers? Use `log` to transform price into a new variable, `price_log`, and take these steps again.\n",
        "  5. Make a scatterplot of `price_log` and `Beds`. Describe what you see. Use `.groupby()` to compute a desciption of `Price` conditional on/grouped by the number of beds. Describe any patterns you see in the average price and standard deviation in prices.\n",
        "  6. Make a scatterplot of `price_log` and `Beds`, but color the graph by `Room Type` and `Property Type`. What patterns do you see? Compute a description of `Price` conditional on `Room Type` and `Property Type`. Which Room Type and Property Type have the highest prices on average? Which have the highest standard deviation? Does the mean or median appear to be a more reliable estimate of central tendency, and explain why?\n",
        "  7. We've looked a bit at this `price_log` and `Beds` scatterplot. Use seaborn to make a `jointplot` with `kind=hex`. Where are the data actually distributed? How does it affect the way you think about the plots in 5 and 6?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
      "metadata": {
        "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
      },
      "source": [
        "**Q5.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
        "\n",
        "1. How did the most recent US Census gather data on race?\n",
        "-It is based on self identification of one or more racial groups as defined by OMB standards. The race options were White, Black/African American, American Indian/Alaska Native, Asian, Native Hawaiian, or other. There was also ethnicity for Hispanic or Latino and not Hispanic or Latino.\n",
        "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
        "-This data is important for a multitude of reasons. First it shows the diversity of America, states, and towns through the diversity index. It can also be used to identify trends of oppression, redlining, gerrymandering and other racial problems that are systemic in America. Lastly, it can show trends in how America is changing, developing, and unifying as a nation. This data plays a huge factor in politics, from gerrymandering to improving diversity, to hate groups, what racial groups are where sadly still plays a massive role in American politics. Especially as we see more racial tentions flair amungst republicans on the Mexican boarder. Quality of data matters greatly in order to properly be able to anylize the data and find patterns that can lead to the identification of oppression, redlining, and other negative race-baced problems happening all over America.\n",
        "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
        "-I feel that the exact wording of the question was far too confusing. They had many boxes for combinations of different racial groups and ethnicities, which I struggled to interpret after 5 minutes. Also, there is not a uniform number of groups that are included on all Census collections which in my opinion is plain stupid. Simplicity is key; there needs to be one question asked on all Census collections with simple to understand race boxes, descriptions of what entails each race/ethnicity, and a uniform expansive number of racial group options. The fact you can select more than one race was a great recent addition in 2010 and should definitly be kept.\n",
        "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
        "-To gather sex, there is a male or female box with the question \"what is Person1's sex\" but have updated to sex assigned at birth in recent trials. For gender only began being asked about in 2021 and asks if you identify as male, female, transgender, or none of these. I feel that there should be some ability to write in a different gender identity, or at least maybe a side box with many of the most common, not listed, gender identities. Every community should be represented somehow.\n",
        "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
        "-As long as sex has a uniform way of being mesured \"male/female\" or \"m/f\" I feel this would be easy to clean. The problem with gender and sexual identity is the sheer number of different indentities that people identify with, which can be very hard to account for. Just having the \"other\" catigory can contain a massive array of different identities, and as many call both a spectrem, both sides can be listed in this other catigory. This is where I feel that some sort of grouping needs to be done in the other catigory. For example for sexual orintation it could be group by if someone is attracted to zero, one, two, or more genders. For race there are simply, currently, too many confusing catigories that can make the data very hard to devide up and may make it difficult to draw meany meaningful conclusions. For example having a \"more than one race\" box tells you very little about a person, where these could be the most important data points. It can show the intersection of two racial groups and whether trends continue of somone who belongs to both.\n",
        "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?\n",
        "-First off, there are great privacy concerns with this. Ethically I feel it is wrong to try to assume someones personal characteristics and then use that assumtion to make decisions about this person. This can lead to ethically unsound people/buisnesses to impute race of canidits, or try to find the sexuality of random people. Beyond ethical concerns, imputing characteristics like this would most likely prove very inconsistant as people are multidimensional and very difficult to predict."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f38f2fd-6381-481d-bba9-017f3d363426",
      "metadata": {
        "id": "2f38f2fd-6381-481d-bba9-017f3d363426"
      },
      "source": [
        "**Q6.** Open the `./data/CBO_data.pdf` file. This contains tax data for 2019, explaining where the money comes from that the U.S. Federal Government Spends in terms of taxation on individuals/families and payroll taxes (the amount that your employer pays in taxes on your wages).\n",
        "\n",
        "For some context, the Federal government ultimately spent about $4.4 trillion in 2019, which was 21% of GDP (the total monetary value of all goods and services produced within the United States). Individual Income Taxes is the amount individuals pay on their wages to the Federal government, Corporate Income Taxes is the taxes individuals pay on capital gains from investment when they sell stock or other financial instruments, Payroll Taxes is the tax your employer pays on your wages, Excises and Customs Duties are taxes on goods or services like sin taxes on cigarettes or alcohol, and Estate and Gift Taxes are taxes paid on transfers of wealth to other people.\n",
        "\n",
        "1. Get the Millions of Families and Billions of Dollars data into a .csv file and load it with Pandas.\n",
        "2. Create a bar plot of individual income taxes by income decile. Explain what the graph shows. Why are some values negative?\n",
        "3. Create a bar plot of Total Federal Taxes by income decile. Which deciles are paying net positive amounts, and which are paying net negative amounts?\n",
        "4. Create a stacked bar plot for which Total Federal Taxes is grouped by Individual Income Taxes, Payroll Taxes, Excises and Customs Duties, and Estate and Gift Taxes. How does the share of taxes paid vary across the adjusted income deciles? (Hint: Are these the kind of data you want to melt?)\n",
        "5. Below the Total line for Millions of Families and Billions of Dollars, there are data for the richest of the richest families. Plot this alongside the bars for the deciles above the Total line. Describe your results.\n",
        "6. Get the Percent Distribution data into a .csv file and load it with Pandas. Create a bar graph of Total Federal Taxes by income decile.\n",
        "7. A tax system is progressive if higher-income and wealthier individuals pay more than lower-income and less wealthy individuals, and it is regressive if the opposite is true. Is the U.S. tax system progressive in terms of amount paid? In terms of the percentage of the overall total?\n",
        "8. Do the rich pay enough in taxes? Defend your answer."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}